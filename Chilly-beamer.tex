% !TEX encoding = UTF-8 Unicode
% !TEX TS-program = XeLaTeX
% !TEX spellcheck = English
% !TEX pdfSinglePage



{\let~\catcode~13=13\def^^M{^^J}~` 12~`\%12~`~12\xdef\asciiart{
                                                                                  
            ...                         .          ..       ..                    
         xH88"`~ .x8X      .uef^"      @88>  x .d88"  x .d88"    ..               
       :8888   .f"8888Hf :d88E         %8P    5888R    5888R    @L                
      :8888>  X8L  ^""`  `888E          .     '888R    '888R   9888i   .dL        
      X8888  X888h        888E .z8k   .@88u    888R     888R   `Y888k:*888.       
      88888  !88888.      888E~?888L ''888E`   888R     888R     888E  888I       
      88888   %88888      888E  888E   888E    888R     888R     888E  888I       
      88888 '> `8888>     888E  888E   888E    888R     888R     888E  888I       
      `8888L %  ?888   !  888E  888E   888E    888R     888R     888E  888I       
       `8888  `-*""   /   888E  888E   888&   .888B .  .888B .  x888N><888'       
         "888.      :"   m888N= 888>   R888"  ^*888%   ^*888%    "88"  888        
           `""***~"`      `Y"   888     ""      "%       "%            88F        
                               J88"                                   98"         
                               @%                                   ./"           
                             :"                                    ~`             
                                                                                  
}}\makeatletter



\documentclass[14pt,aspectratio=1610]{beamer}
	\beamertemplatenavigationsymbolsempty
	\setbeamercovered{transparent}
	\setbeamersize{text margin left=3mm,text margin right=3mm}
	\overfullrule1em
	\def\pp{\pause\par}
	\advance\parskip\fill
	\def\CMH{\gdef\beamer@currentmode{handout}}
	\def\CMB{\gdef\beamer@currentmode{beamer}}

\catcode`æ¿€13 \defæ¿€#1{\lccode`~`#1\lowercase{\catcode`#113\def~}}
	æ¿€è‰²#1!#2#3#4#5#6#7{\definecolor{#1}{HTML}{#2#3#4#5#6#7}}
	% https://marketing.illinois.edu/brand/design/color
	è‰²Illini Orange!FF552E		è‰²Altgeld!DD3403				è‰²Illini Blue!13294B		
	è‰²Alma! 1E3877è‰²Industrial! 1D58A7è‰²Arches! 009FD4è‰²Cloud! F8FAFCè‰²Heritage! F5821E
	è‰²Alma2!4D69A0è‰²Industrial2!5783BCè‰²Arches2!7FC3E1è‰²Cloud2!E8E9EBè‰²Heritage2!E56E15
	è‰²Alma3!849BC1è‰²Industrial3!90AED5è‰²Arches3!A6D7EBè‰²Cloud3!DDDEDEè‰²Heritage3!CE5E11
	è‰²Alma4!AFC7DBè‰²Industrial4!CAD9EFè‰²Arches4!D2EBF5è‰²Cloud4!D2D2D2è‰²Heritage4!B74D04

	\setbeamercolor{normal text}{bg=Illini Blue,fg=Cloud}
	\setbeamercolor{structure}{fg=Illini Orange}
	\setbeamercolor{alerted text}{fg=Heritage}
	\setbeamercolor{example text}{fg=Arches}

\usepackage{xurl}
	\hypersetup{pdfsubject=94A24; 68P30; math.IT}
	\hypersetup{colorlinks,linkcolor=Heritage,citecolor=Altgeld,urlcolor=Arches}

\usepackage{mathtools}

\usepackage[warnings-off={mathtools-colon,mathtools-overbracket}]{unicode-math}
	\setmainfont{Times}
	\setsansfont{HelveticaNeue-Light}
	\setmonofont{Menlo}
	\setmathfont[sans-style=literal]{texgyrepagella-math.otf}
	
	\DeclareMathOperator*\argmax{argmax}
	\DeclareMathOperator*\mybest{do-my-best}
	\DeclareMathOperator\hwt{hwt}
	\DeclareMathOperator\poly{poly}
	\def\P{P_\mathrm e}
	
	\def\({\bigl(}	\def\){\bigr)}	æ¿€ï¼ˆ{\Bigl(}		æ¿€ï¼‰{\Bigr)}		
	æ¿€ï¼»{\bigl[}		æ¿€ï¼½{\bigr]}		æ¿€ã€Œ{\Bigl[}		æ¿€ã€{\Bigr]}		
	æ¿€ï½›{\bigl\{}	æ¿€ï½{\bigr\}}	æ¿€ã€{\Bigl\{}	æ¿€ã€{\Bigr\}}	
	æ¿€ã€{\lvert}		æ¿€ã€‘{\rvert}	
	
	æ¿€ã’{\log}		æ¿€ã‘{\ln}		
	æ¿€Ë†{\hat}		æ¿€Â¯{\bar}		
	æ¿€ï½œ{\mid}		æ¿€ï¼š{\colon}		æ¿€ï¼›{\mathrel;\nobreak}		
	æ¿€Ã·{\frac}		æ¿€âˆš{\sqrt}		æ¿€Â¬{\limits}		
	æ¿€â€ #1â€ {{\text{#1}}}				
	æ¿€â‹†{\raisebox{1ex}{$\star$}}
	
	\def\J#1{^{(#1)}}
	\def\W#1{W\J{#1}}
	\def\WW#1#2{(\W{#1})\J{#2}}
	\def\WWW#1#2#3{\(\WW{#1}{#2}\)\J{#3}}
	\def\WWWW#1#2#3#4{ï¼ˆ\WWW{#1}{#2}{#3}ï¼‰\J{#4}}
	\def\Q#1{Q\J{#1}}
	\def\QQ#1#2{(\Q{#1})\J{#2}}
	\def\QQQ#1#2#3{\(\QQ{#1}{#2}\)\J{#3}}
	\def\G#1{G\J{#1}}
	\def\GG#1#2{\G{#1#2}}

\usepackage{tikz,tikz-cd}
	\pgfmathsetseed{32652}\let\PMP\pgfmathparse\def\PMR{\pgfmathresult}
	\let\PMS\pgfmathsetmacro\let\PMT\pgfmathtruncatemacro\let\PMD\pgfmathdeclarefunction
	% https://tex.stackexchange.com/q/420034/
	\PMD*{axis_height}0{\begingroup\pgfmathreturn.25em\endgroup}
	\PMD*{rule_thickness}0{\begingroup\pgfmathreturn.06em\endgroup}
	\tikzset{
		every picture/.style={cap=round,join=round,line width=rule_thickness},
		% https://tex.stackexchange.com/q/146908/
		alt/.code args={<#1>#2#3}{\alt<#1>{\pgfkeysalso{#2}}{\pgfkeysalso{#3}}},
		uncover/.style={alt=<#1>{}{opacity=.15}},
	}
	\def\channeltree#1<#2:#3v#4v#5;{
		\edef\d{#1}\edef\dept{#2}\edef\zbottom{#3}\edef\z{#4}\edef\ztop{#5}
		\ifnum\d<\dept
		\ifdim\z pt<\ztop pt
		\ifdim\z pt>\zbottom pt{
			\advance\c@beamerpauses1
			\edef\dplus{\the\numexpr\d+1}
			{
				\PMS\zup{\z*(256-\z)/128}
				\onslide<.->{\draw(\d,\z/32)--(\dplus,\zup/32);}
				\channeltree\dplus<\dept:\zbottom v\zup v\ztop;
			}
			{
				\PMS\zdown{\z^2/128}
				\onslide<.->{\draw(\d,\z/32)--(\dplus,\zdown/32);}
				\channeltree\dplus<\dept:\zbottom v\zdown v\ztop;
			}
		}\fi\fi\fi
		\onslide<.->{\fill(\d,\z/32)circle(1pt);}
	}

\usepackage{pgfplotstable,booktabs,colortbl}
	\pgfplotsset{compat/.cd,show suggested version=false,=1.17}
	\pgfplotstableset{
		every head row/.style={before row=\toprule,after row=\midrule},
		every last row/.style={after row=\bottomrule},string type,
	}
	\def\arraystretch{1.44}

\title[Complexity \& 2-Moment of Communication]{
	Complexity and Second Moment of	\\
	the Mathematical Theory of Communication
}
\author[H-P\ Wang]{Hsin-Po WANG}
\institute{Department of Mathematics, University of Illinois at Urbana--Champaign}
\date[2021-04]{2021-04-01 PhD Defense Presentation}

\begin{document}
\message{\asciiart}
\makeatletter

\def\linkfil#1{\vbox to#1cm{\hbox{.}\vfil\hbox to3mm{\hfil.}}\vfil}
\defbeamertemplate*{sidebar left}{thinbold}{
	\pgfsetfillopacity0
	\hyperlinkframeendprev{\linkfil1}
	\hyperlinkslideprev{\linkfil3}
	\hyperlinkslidenext{\linkfil3}
	\hyperlinkframestartnext{\linkfil1}
	\pgfsetfillopacity1\vfilneg\vfilneg
}

\frame\maketitle

\defbeamertemplate*{sidebar right}{thinbold}{
	\tikz[remember picture,overlay,x=3mm,y=\paperheight]{\footnotesize
		\PMS\olfrac{\insertoverlaynumber/(\insertframeendpage+1-\insertframestartpage)}
		\path[save path=\stare,yscale={1/max(\insertmainframenumber-1,1)}]
			(0,0)-|(-1,1-\insertframenumber)-|+(\olfrac,1)-|cycle;
		\tikzset{banner/.pic={\node at(-.55,-.5)[rotate=-90]
			{\beamer@shorttitle~~\beamer@shortdate~~\beamer@shortauthor};}}
		\fill[use path=\stare,Alma3]pic[Alma4]{banner};
		\clip[use path=\stare]pic[Illini Blue]{banner};
	}
}

\CMB

\frame{{Noisy channel}
	The sender inputs  $Xâ‚Â³Â²=\texttt{11001001 00001111 11011010 10100010}$.
	\pp
	The channel outputs $Yâ‚Â³Â²=\texttt{1--01-01 ----1--- -101---0 --0--0-0}$.
}

\frame{{Noisy channel}
	Sender inputs $Xâ‚Â³Â²âˆˆğ”½_qÂ³Â²$, where $ğ”½_q$ is called input alphabet.	\\
	WLoG, we may assume $ğ”½_q$ is a finite field [new idea].
	
	The channel outputs $Yâ‚Â³Â²$ according to transition probabilities
	$P\{Y_j=yï½œX_j=x\}=W(y|x)$ independently for each $j$.
}

\frame{{Noisy-channel coding}
	The encoder inputs $Xâ‚Â³Â²âˆˆâ„¬âŠŠğ”½_q^{32}$ into a channel.	\\
	$â„¬$ is a \emph{block code} (sometimes a \emph{codebook}) of block length $N=32$.
	\pp
	The channel outputs $Yâ‚Â³Â²$ according to $W(y|x)$.
	\pp
	The decoder, seeing $Yâ‚Â³Â²=yâ‚Â³Â²$, maximizes the posterior probability	\\
	$Ë†Xâ‚Â³Â²(yâ‚Â³Â²)â‰”{\alt<+(1)>{\color{alerted text.fg}\mybest}
		\argmaxÂ¬_{xâ‚Â³Â²âˆˆâ„¬}}P\{Xâ‚Â³Â²=xâ‚Â³Â²ï½œYâ‚Â³Â²=yâ‚Â³Â²\}$.
}

\frame{{Noisy-channel coding theorem}
	Channel capacity $Câ‰”\supÂ¬_{\!Xâˆ¼Q\!}I(Xï¼›Y)$ (supremum over input distribution).	\\
	Block length is $N$.	\\
	Error probability is $\Pâ‰”P\{Ë†Xâ‚^Nâ‰ Xâ‚^N\}$.	\\
	Code rate is $Râ‰”ã‘ã€â„¬ã€‘\divã‘ã€ğ”½_q^Nã€‘$.	\hfill(recall that $â„¬âŠ‚ğ”½_q^N$)	
	\pp
	[Shannon 1948]	\\
	\emph{
		One can find block codes $â„¬$ such that $\Pâ†’0$ and $Râ†’C$ as $Nâ†’âˆ$.	\\
		(And $C$ is the greatest number that allows this to happen.)
	}
}

\frame{{2nd-order term of coding}
	How fast do error probability $\P$ and code rate $R$ converge to $0$ and $C$	\\
	as block length $Nâ†’âˆ$? Characterize functions ``$\P(N)$'' and ``$R(N)$''.
	\pp
	When $R$ is fixed, $\Pâ‰ˆe^{-N}$; or equivalently, $-ã‘\Pâ‰ˆN$.	\\
	Fano \cite{Fano61},
	Gallager \cite{Gallager65},
	Shannon--Gallager--Berlekamp \cite{SGB67},
	\cite{Gallager68},
	\cite{Gallager73},
	Blahut \cite{Blahut74},
	Barg--Forney \cite{BF02},
	FÃ bregas--Land--Martinez \cite{FLM11},
	Domb--Zamir--Feder \cite{DZF16}.
	\pp
	When $\P$ is fixed, $Râ‰ˆC-N^{-1/2}$; or equivalently, $(C-R)^{-2}â‰ˆN$.	\\
	Wolfowitz \cite{Wolfowitz57},
	Weiss \cite{Weiss60},
	Dobrushin \cite{Dobrushin61},
	Strassen \cite{Strassen62},
	Baron--Khojastepour--Baraniuk \cite{BKB04},
	Hayashi \cite{Hayashi09},
	Polyanskiy--Poor--Verdu \cite{PPV10}.
}


\frame{{Joint 2nd-order term of coding}
	When both $R$ and $\P$ vary, $(\P,R)â‰ˆ(e^{-N^Ï€},C-N^{-Ï})$ where $Ï€+2Ï=1$;	\\
	or equivalently, $(-ã‘\P)(C-R)^{-2}â‰ˆN$.	\\
	AltuÄŸ--Wagner \cite{AW10},
	Polyanskiy--VerdÃº \cite{PV10},
	\cite{AW14},
	Hayashi--Tan \cite{HT15}.
	\pp
	This is a two-sided bound:	\\
	A code $â„¬$ exists such that $(-ã‘\P)(C-R)^{-2}â‰ˆN$.	\\
	No code $â„¬$ exists such that $(-ã‘\P)(C-R)^{-2}â‰« N$.
	\pp
	Block length $N$ is your income;	\\
	invest in error probability $\P$ or in code rate $R$ or in both.
}

æ¿€åˆ†#1#2{Ã·{#1\rule{0ex}{1.5ex}}{#2\rule[-1ex]{0ex}{0ex}}}
\pgfplotstableread{
	Par	Paradigm						&	{Random variable}					
	LLN	{law of large numbers}			&	Â¯Xâ†’Î¼								
	LDP	{large deviation principle}		&	â„™\{Â¯X-Î¼>x\}â‰ˆe^{-nI(x)}				
	CLT	{central limit theorem}			&	Â¯X-Î¼âˆ¼ğ’©(0,Ïƒ/âˆšn)						
	MDP	{moderate deviation principle}	&	åˆ†{-ã‘â„™\{Â¯X-Î¼>Î³_nx\}}{Î³_nÂ²}â‰ˆnI(x)	
}\tableTrinity
\pgfplotstableread{
	Par	&	{Random code}		{Polar code}				
	LLN	&	(\P,R)â†’(0,C)		(\P,R)â†’(0,C)				
	LDP	&	\Pâ‰ˆe^{-N}			\Pâ‰ˆe^{-N^{0.99}}			
	CLT	&	C-Râ‰ˆN^{-1/2}		C-Râ‰ˆN^{-0.49}				
	MDP	&	åˆ†{-ã‘\P}{(C-R)Â²}â‰ˆN	åˆ†{-ã‘\P}{(C-R)Â²}â‰ˆN^{0.99}	
}\tableCoding
\pgfplotstablecreatecol[create col/copy column from table=\tableCoding{Random code}]
	{Random code}\tableTrinity
\pgfplotstablecreatecol[create col/copy column from table=\tableCoding{Polar code}]
	{Polar code}\tableTrinity
\pgfplotstablemodifyeachcolumnelement{Paradigm}\of\tableTrinity\as\cell
	{\edef\cell{\noexpand\footnotesize\unexpanded\expandafter{\cell}}}
\pgfplotstablemodifyeachcolumnelement{Random variable}\of\tableTrinity\as\cell
	{\edef\cell{$\unexpanded\expandafter{\cell}$}}
\pgfplotstablemodifyeachcolumnelement{Random code}\of\tableTrinity\as\cell
	{\edef\cell{$\unexpanded\expandafter{\cell}$}}
\pgfplotstablemodifyeachcolumnelement{Polar code}\of\tableTrinity\as\cell
	{\edef\cell{$\unexpanded\expandafter{\cell}$}}

\frame{{2nd-order term analog}
	$$\pgfplotstabletypeset[
		columns={Paradigm,Random variable,Random code},
		columns/Random variable/.style={column type={>{\onslide<2->}c}},
		columns/Random code/.style={column type={>{\onslide<3>}c}},
	]\tableTrinity$$
}

\frame{{However...}
	Achievability via random coding assumes exponential complexity	\\
	due to the usage of the maximum a posteriori decoder $\argmaxÂ¬_{xâ‚Â³Â²âˆˆâ„¬}$.
	\pp
	Goal:
	Comparable performance, but with a low-complexity $\mybestÂ¬_{xâ‚Â³Â²âˆˆâ„¬}$.
}

\frame{{2nd-order term goal}
	$$\pgfplotstabletypeset[
		columns={Paradigm,Random code,Polar code},
		columns/Polar code/.style={
			column type={>{\onslide<2>}c},column name=Low-complexity code},
	]\tableTrinity$$
	
	\hfill\onslide<2>($Ï€,Ï>0$ and $Ï€+2Ï<1)$
}

\pgfplotstableread{
	Par		BEC			SBDMC		p-ary	q-ary	finite		BDMC	a-finite
	LLN		Arikan09	Arikan09	STA09	STA09	STA09		SRDR12	w		
	LDPâ‹†	AT09		AT09		STA09	MT10	Sasoglu11	HY13	w		
	CLTâ‹†	KMTU10		HAU14		BGNRS18	w		w			w		w		
	MDPâ‹†	GX15		GX15		BGS18	w		w			w		w		
	LDP		KSU10		KSU10		w		w		w			w		w		
	CLT		FHMV18		GRY20		w		w		w			w		w		
	MDP		w			w			w		w		w			w		w		
}\tableRefarray
\def\assigncontent#1{\pgfkeyssetvalue{/pgfplots/table/@cell content}{#1}}
\def\decodecontent#1#2\relax{
	\if\pgfplotstablecol0	\assigncontent{#1#2}
	\else\if#1w				\assigncontent{??}
	\else					\assigncontent{\footnotesize\cite{#1#2}}
	\fi\fi
}
\frame{{Polar coding}
	$$\pgfplotstabletypeset[
		columns/Par/.style={column type={>{\onslide<1->}c}},
		columns/BEC/.style={column type={>{\onslide<2->}c}},
		columns/SBDMC/.style={column type={>{\onslide<2->}c}},
		columns/p-ary/.style={column type={>{\onslide<3->}c}},
		columns/q-ary/.style={column type={>{\onslide<4->}c}},
		columns/finite/.style={column type={>{\onslide<4->}c}},
		columns/BDMC/.style={column type={>{\onslide<4->}c}},
		columns/a-finite/.style={column type={>{\onslide<5->}c}},
		assign cell content/.code={\decodecontent####1\relax}
	]\tableRefarray$$
}

\frame{{Polar coding road map}
	\textcolor{example text.fg}{Channel transformation}
		manipulates channels.
	
	\textcolor{example text.fg}{Channel tree}
		is the result of recursive channel transformation.
	
	\textcolor{example text.fg}{Channel parameter}
		measures the channels and keep track of the tree.
	
	\textcolor{example text.fg}{Channel process}
		is a syntax candy paraphrasing the tree.
	
	\textcolor{example text.fg}{Channel polarization}
		is a phenomenon that channels become extreme.
}

\frame{{Channel transformation}
	Consider a channel $W=(Xï½œY)$, where input is $X$, output is $Y$.	\\
	Make two i.i.d.\ copies $(Xâ‚ï½œYâ‚)$ and $(Xâ‚‚ï½œYâ‚‚)$.
	\pp
	$\W1â‰”(Xâ‚-Xâ‚‚ï½œYâ‚Â²)$;	\\
	$\W2â‰”(Xâ‚‚ï½œ(Xâ‚-Xâ‚‚)Yâ‚Â²)$.	\hfill(juxtaposition is tuple concatenation)
}

\frame{{Channel transformation (other kernel)}
	$Uâ‚Â²$: two free variables; $G$: a $2Ã—2$ matrix (called kernel);	\\
	$Xâ‚Â²â‰”Uâ‚Â²Â·G$: matrix multiplication; channels generate $Yâ‚Â²$ given $Xâ‚Â²$.
	
	$\W1â‰”(Uâ‚ï½œYâ‚Â²)$;	\\
	$\W2â‰”(Uâ‚‚ï½œUâ‚Yâ‚Â²)$	\hfill(juxtaposition is tuple concatenation).
}

\frame{{Channel transformation (larger kernel)}
	$Uâ‚^â„“$: many free variables; $G$: an $â„“Ã—â„“$ matrix kernel;	\\
	$Xâ‚^â„“â‰”Uâ‚^â„“Â·G$; channels generate $Yâ‚^â„“$ given $Xâ‚^â„“$.
	\pp
	$\W1â‰”(Uâ‚ï½œYâ‚^â„“)$;	\\
	$\W2â‰”(Uâ‚‚ï½œUâ‚Yâ‚^â„“)$;	\\
	$\W3â‰”(Uâ‚ƒï½œUâ‚Â²Yâ‚^â„“)$;	\\
	$\phantom{\W{â„“-1}}â‹®$	\\
	$\W{â„“-1}â‰”(U_â„“ï½œUâ‚^{â„“-2}Yâ‚^â„“)$;	\\
	$\Wâ„“â‰”(U_â„“ï½œUâ‚^{â„“-1}Yâ‚^â„“)$.
	\pause
	\tikz[x=1em,y=-1em,overlay,shift={(7,-6)}]{
		\draw
			(0,.5)rectangle node(G){$Â·G$}(3,5.5)
			foreach\j in{1,...,5}{
				(-2,\j)node(U\j){$U_\j$}(U\j)-|(0,3)
				(5,\j)node(X\j){$X_\j$}(3,3)|-(X\j)
				(8,\j)node(Y\j){$Y_\j$}(X\j)--(Y\j)
			}
		;
	}
}

\frame{{Channel tree}
	Channel $W$ grows $\W1,\W2,â€¦,\Wâ„“$.
	\pp
	For each $i$, channel $\W i$ grows $\WW i1,â€¦,\WW iâ„“$.
	\pp
	For each $j$, channel $\WW ij$ grows $\WWW ij1,â€¦,\WWW ijâ„“$.
	\pp
	$$\tikz[
		grow=right,
		level/.style={
			level distance=2em*####1,sibling distance=8em/2^####1,nodes={scale=7/8}
		}
	]{
		\node{$W$}
		child foreach\i in{1,2}{
			node{$\W\i$}
			child foreach\j in{1,2}{
				node{$\WW\i\j$}
				child foreach\k in{1,2}{
					node{$\WWW\i\j\k$}
				}
			}
		}
	}$$
}

\frame{{Dynamic kernel [new idea*]}
	Channel $W$ grows $\W1,\W2,â€¦,\Wâ„“$ using $G$.
	\pp
	For each $i$, channel $\W i$ grows $\WW i1,â€¦,\WW iâ„“$ using $\G i$.
	\pp
	$âˆ€j$, channel $\WW ij$ grows $\WWW ij1,â€¦,\WWW ijâ„“$ using $\GG ij$.
	\pp
	$$\tikz[
		grow=right,
		level/.style={
			level distance=2em*####1,
			sibling distance=8em/2^####1,
			nodes={scale=7/8}
		}
	]{
		\node{$W$}
		child foreach\i in{1,2}{
			node{$\W\i$}
			child foreach\j in{1,2}{
				node{$\WW\i\j$}
				child foreach\k in{1,2}{
					node{$\WWW\i\j\k$}
				}
			}
		}
	}$$
}

%	$W$ grows $\W1$.
%	$\W1$ grows $\WW11$ and $\WW12$;
%	$\W2$ grows $\WW21$ and $\WW22$.
%	$\WW11$ grows $\WWW111$ and $\WWW112$;
%	$\WW12$ grows $\WWW121$ and $\WWW122$;
%	$\WW21$ grows $\WWW211$ and $\WWW212$;
%	$\WW22$ grows $\WWW221$ and $\WWW222$.

\frame{{Channel parameter ($â„“=2$ and $n=3$ exmaple)}
	Block length $N=â„“^n$; for instance $8=2Â³$.
	\pp
	Select indices $ğ’¥âŠ†\{1,â€¦,â„“\}^n$; for instance $\{122,212,221,222\}âŠ†\{1,2\}Â³$.	\\
	Code rate $R=ã€ğ’¥ã€‘/N=4/8$ (nontrivial, due to implementation details).
	\pp
	Error probability $\Pâ‰¤âˆ‘Â¬_{ijkâˆˆğ’¥}Hï¼ˆ\WWW ijkï¼‰$ (nontrivial, due to details);	\\
	$H(Xï½œY)$ is conditional entropy with base-$q$ logarithm.
}

\frame{{It suffices to understand}
	$H(W),H(\W i),H\(\WW ij\),Hï¼ˆ\WWW ijkï¼‰,Hï¼ˆ\WWWW ijklï¼‰,â€¦$\kern-2em
	\pp
	Block length $N$ will be $â„“^â€ where we stopâ€ $.
	\pp
	Code rate $R$ will be the fraction of small $H$-values.
	\pp
	Block error probability $\P$ will be $âˆ‘Â¬_â€ thoseâ€ $ small $H$-values.
}

\frame{{Channel process (a powerful syntax candy)}
	$ğ˜â‚€â‰”W$.	\\
	$ğ˜_{n+1}â‰”ğ˜_n^{(ğ˜‘_{n+1})}$, where
	$ğ˜‘_{n+1}âˆˆ\{1,2,â€¦,â„“\}$ i.i.d.\ uniform branch chooser.
	\pp
	$ğ˜_nâ‰”H(ğ˜_n)$.
	\pp
	Decide depth $n$, then block length is $N=â„“^n$.	\\
	Decide threshold $Î¸$, then code rate is $R=ğ˜—\{ğ˜_n<Î¸\}$.	\\
	Error probability is $\P<âˆ‘â€ small â€ ğ˜_n<âˆ‘Î¸=RNÎ¸â‰¤NÎ¸$.
}

\frame{{Channel polarization}
	$ğ˜_nâ‰”H(ğ˜_n)$ is a martingale. (Invoke Doob's martingale convergence)	\\
	$ğ˜_nâ†’ğ˜_âˆ$ a.e.\ as $nâ†’âˆ$; turns out $ğ˜_âˆâˆˆ\{0,1\}$ and $ğ˜—\{ğ˜_âˆ=1\}=ğ˜â‚€$.
	
	\onslide<+>{}
	$$\tikz{
		\path(0,0)circle(2pt)(0,4)circle(2pt);
		\channeltree0<6:0v49v128;
		\onslide<.(7)->{
			\draw[alerted text.fg](6,1/4)--+(1,0)node[right]{threshold $Î¸$};}
	}$$
}


\frame{{It suffices to understand}
	\par
	{\LARGE$ğ˜—\{ğ˜_n<â€ thresholdâ€ \}>C-â€ gapâ€ $.\par}
	\pp
	Goal: $ğ˜—ï½›ğ˜_n<e^{-â„“^{Ï€n}}ï½>C-â„“^{-Ïn}$ for large $n$, where $Ï€+2Ï<1$.	\\
	Then: $N=â„“^n$ and $\P<Ne^{-N^Ï€}â‰ˆe^{-N^Ï€}$ and $R>C-N^{-Ï}$ .
}

\frame{{Proof outline}
	\textcolor{example text.fg}{Local LDP behavior:}
	$Z(\W j)â‰¤â„“e^{qZ(W)â„“}(qZ(W))^{âŒˆj^2/3â„“âŒ‰}$,	\\
	where $Z$ is a parameter such that $Zâ‰¤qÂ³âˆšH$ and $Hâ‰¤qÂ³âˆšZ$.
	
	\textcolor{example text.fg}{Local CLT behavior:}
	$âˆ‘Â¬_{j=1}^â„“h(H(\W j))<4â„“^{1/2+Î±}$,	\\
	where $Î±=ã‘(ã‘â„“)/ã‘â„“$ and $h(z)â‰”\min(z,1-z)^Î±$.
	
	\textcolor{example text.fg}{Global MDP behavior:}
	$ğ˜—ï½›ğ˜_n<e^{-â„“^{Ï€n}}ï½>C-â„“^{-Ïn}$,
	where $Ï€+2Ï<1$, given local LDP and local CLT behaviors.
}

\frame{{Local LDP behavior 1/3}
	Want to prove $Z(\W j)â‰¤â„“e^{qzâ„“}(qz)^{âŒˆj^2/3â„“âŒ‰}$ where $zâ‰”Z(W)$.
	\pp
	Fundamental theorem of polar:
	$Z(\W j)â‰¤âˆ‘Â¬_{u_{j+1}^â„“âˆˆğ”½_q^{â„“-j}}z^{\hwt(0â‚^{j-1}1_ju_{j+1}^â„“Â·G)}$.	\\
	RHS is the weight enumerator of a coset code.
	\pp
	$\W1â‰”(Uâ‚ï½œYâ‚^â„“)$;	\\
	$\W2â‰”(Uâ‚‚ï½œUâ‚Yâ‚^â„“)$;	\\
	$\phantom{\W2}â‹®$	\\
	$\Wâ„“â‰”(U_â„“ï½œUâ‚^{â„“-1}Yâ‚^â„“)$.
	\tikz[x=1em,y=-1em,overlay,shift={(6,-5)}]{
		\draw
			(0,.5)rectangle node(G){$Â·G$}(3,5.5)
			foreach\j in{1,...,5}{
				(-2,\j)node(U\j){$U_\j$}(U\j)-|(0,3)
				(5,\j)node(X\j){$X_\j$}(3,3)|-(X\j)
				(8,\j)node(Y\j){$Y_\j$}(X\j)--(Y\j)
			}
		;
	}
}

\frame{{Local LDP behavior 2/3}
	Want $âˆ‘Â¬_{u_{j+1}^â„“}z^{\hwt(0â‚^{j-1}1_ju_{j+1}^â„“Â·G)}
		â‰¤â„“e^{qzâ„“}(qz)^{âŒˆj^2/3â„“âŒ‰}$ for some $G$.
	\pp
	Draw random $ğ”¾$ instead; $ğ”¼[â€ LHSâ€ ]=q^{-j}(1+(q-1)z)^â„“â‰¤q^{-j}(1+qz)^â„“$.
	\pp
	Compare $(qz)^w$-coefficients:
	$q^{-j}\binomâ„“w$ vs $â„“Ã·{â„“^{w-âŒˆj^2/3â„“âŒ‰}}{(w-âŒˆj^2/3â„“âŒ‰)!}$.
	\pp
	Simplify: $2^{-j}\binomâ„“{âŒˆj^2/3â„“âŒ‰}\binom{â„“-âŒˆj^2/3â„“âŒ‰}{w-âŒˆj^2/3â„“âŒ‰}$
	vs $â„“\binomâ„“{w-âŒˆj^2/3â„“âŒ‰}$.
}

\PMD{h2o}1{% := h2(sin(#1)^2)
	\PMS\sin{sin(#1)}\PMS\cos{cos(#1)}%
	\ifdim\sin pt=0pt%
		\PMP{0}%
	\else\ifdim\cos pt=0pt%
		\PMP{0}%
	\else%
		\PMP{(-\sin*ln(\sin)*\sin-\cos*ln(\cos)*\cos)*2.88539}% 2/ln(2)
	\fi\fi%
}
\frame{{Local LDP behavior 3/3}
	Boils down to $2^{-j}\binomâ„“{âŒˆj^2/3â„“âŒ‰}$ vs $â„“$;
	ignore $âŒˆâŒ‰$ and $â„“$; compare $\binomâ„“{j^2/3â„“}$ vs $2^j$.
	\pp
	$\binomâ„“dâ‰ˆ2^{â„“h_2(d/â„“)}$ for $d=Î˜(â„“)$. (Large deviations theory.)	\\
	Hence $h_2(j^2/3â„“^2)$ vs $j$, which becomes $âˆš{3x}$ vs $h_2(x)$.
	\pp
	$$\tikz[scale=4]{
		\path(0,0)--(1,1);
		\tikzset{
			shift={(.2,.8)},
			scale={1.2^max(0,\insertoverlaynumber-\c@beamerpauses)},
			shift={(-.2,-.8)},
		}
		\draw[overlay]plot[domain=0:90,samples=90]({sin(\x)^2},{h2o(\x)});
		\draw[overlay]plot[domain=0:1,samples=20](\x^2/e,\x);
		\only<+(10)>{}
	}$$
}

\frame{{Local CLT behavior 1/4}
	Want to prove $âˆ‘Â¬_{i=1}^â„“h(H(\W i))<4â„“^{1/2+Î±}$,	\\
	where $Î±=ã‘(ã‘â„“)/ã‘â„“$ and $h(z)â‰”\min(z,1-z)^Î±$.
	\pp
	Break into three segments
	$\begin{cases}
		âˆ‘Â¬_{i=âŒˆH(W)+â„“^{-1/2+Î±}âŒ‰+1}^â„“h(H(\W i))<â„“^{1/2+Î±},	\\
		âˆ‘Â¬_{i=âŒŠH(W)-â„“^{-1/2+Î±}âŒ‹}^{âŒˆH(W)+â„“^{-1/2+Î±}âŒ‰}h(H(\W i))<2â„“^{1/2+Î±}, \\
		âˆ‘Â¬_{i=1}^{âŒŠH(W)-â„“^{-1/2+Î±}âŒ‹-1}h(H(\W i))<â„“^{1/2+Î±}.
	\end{cases}$
	\pp
	\tikz[overlay,shift={(1,-1)}]{
		\draw(0,0)[domain=0:3.1748]plot(\x^3/16,\x)plot(4-\x^3/16,\x);
		\fill foreach\y in{.1,.2,.3,.5,.8,1.3,2.1}{(\y^3/16,\y)circle(2pt)};
		\fill foreach\y in{.1,.2,.4,.8,1.6}{(4-\y^3/16,\y)circle(2pt)};
	}
}

\frame{{Local CLT behavior 2/4}
	Want $âˆ‘Â¬_{i=j+1}^â„“h(H(\W i))<â„“^{1/2+Î±}$, where $jâ‰”âŒˆH(W)+â„“^{-1/2+Î±}âŒ‰$.
	\pp
	Jensen LHS; want to show $(â„“-j)hï¼ˆÃ·1{â„“-j}âˆ‘Â¬_{i=j+1}^â„“H(\W i)ï¼‰<â„“^{1/2+Î±}$.
	\pp
	$\phantom{\W{â„“-2}}â‹®$	\\
	$\W{â„“-2}â‰”(U_{â„“-2}ï½œUâ‚^{â„“-3}Yâ‚^â„“)$,	\\
	$\W{â„“-1}â‰”(U_{â„“-1}ï½œUâ‚^{â„“-2}Yâ‚^â„“)$,	\\
	$\Wâ„“â‰”(U_â„“ï½œUâ‚^{â„“-1}Yâ‚^â„“)$.
	\hfill$\smash{âˆ‘Â¬_{i=j+1}^â„“}H(\W i)=H(U_{j+1}^â„“ï½œUâ‚^jYâ‚^â„“)$.
}

\frame{{Local CLT behavior 3/4}
	What is $H(U_{j+1}^â„“ï½œUâ‚^jYâ‚^â„“)$?	\hfill($jâ‰”âŒˆH(W)+â„“^{-1/2+Î±}âŒ‰$)
	\pp
	It is the conditional entropy of	\\
	noisy-channel coding.
	\tikz[x=1em,y=-1em,overlay,shift={(9,-2)}]{
		\draw
			(0,.5)rectangle node(G){$Â·G$}(3,5.5)
			foreach\k in{1,...,5}{
				(-2,\k)node(U\k)[opacity={\k<3?0:1}]{$U_\k$}(U\k)-|(0,3)
				(5,\k)node(X\k){$X_\k$}(3,3)|-(X\k)
				(8,\k)node(Y\k){$Y_\k$}(X\k)--(Y\k)
			}
		;
	}
	\pp
	Gallager has good bounds.
}

\frame{{Local CLT behavior 4/4}
	The last segment: $âˆ‘Â¬_{i=1}^{j}h(H(\W i))<4â„“^{1/2+Î±}$.	\\
	Pre-process by Jensen inequality: $jhï¼ˆÃ·1jâˆ‘Â¬_{i=1}^{j+1}H(\W i)ï¼‰<4â„“^{1/2+Î±}$.	\\
	Chain rule: $jhï¼ˆÃ·1jH(Uâ‚^jï½œYâ‚^â„“)ï¼‰$, but what is $H(Uâ‚^jï½œYâ‚^â„“)$?
	\pp
	Wiretap channel [new idea];	\\
	Hayashi has good bounds.
	\tikz[x=1em,y=-1em,overlay,shift={(9,-4)}]{
		\def\comment{\llap{\ifnum\k<3 message \else obscure \fi}}
		\draw
			(0,.5)rectangle node(G){$Â·G$}(3,5.5)
			foreach\k in{1,...,5}{
				(-2,\k)node(U\k){\comment$U_\k$}(U\k)-|(0,3)
				(5,\k)node(X\k){$X_\k$}(3,3)|-(X\k)
				(8,\k)node(Y\k){$Y_\k$}(X\k)--(Y\k)
			}
		;
	}
}

\frame{{A calculus machinery [new idea]}
	Given local LDP behavior: $Z(\W j)â‰¤â„“e^{qZ(W)â„“}(qZ(W))^{âŒˆj^2/3â„“âŒ‰}$	\\
	and local CLT behavior: $âˆ‘Â¬_{j=1}^â„“h(H(\W j))<4â„“^{1/2+Î±}$.
	\pp
	eigen: $ğ˜Œ[h(ğ˜_{n+1})ï½œğ˜â‚€,â€¦,ğ˜_n]â‰¤â„“^{-1/2+3Î±}h(ğ˜_n)$.
	\pp
	en23: $ğ˜—ï½›ğ˜¡_n<e^{-n^{2/3}}ï½>1-H(W)-â„“^{(-1/2+4Î±)n}$.
	\pp
	een13: $ğ˜—ã€ğ˜¡_n<\exp\(-e^{n^{1/3}}\)ã€>1-H(W)-â„“^{(-1/2+4Î±)n}$.
	\pp
	elpin: $ğ˜—ï½›ğ˜¡_n<e^{-â„“^{Ï€n}}ï½>1-H(W)-â„“^{-Ïn}$.
}

\frame{{Summary of the proof}
	For local LDP behavior, we investigate the distance of a random matrix.
	\pp
	For local CLT, noisy-channel coding and wiretap-channel coding.
	\pp
	For the global MDP behavior, a calculus machinery is invented/used.
}

\frame{{Summary of my results so far}
	For all $Ï€+2Ï<1$, there exist codes with	\\
	error probability $\P<e^{-N^Ï€}$	and code rate $R>C-N^{-Ï}$.
	\pp
	When only $2Ã—2$ kernels are allowed, at least $Ï€,Ï>0$.
	\pp
	It happens that they have complexity $O(ã’N)$ per bit.
	\pp
	Can we reduce the complexity further	\\
	(at the expense of worse performance etc)?
}

\frame{{Prune the tree for simplicity}
	The bottom channel is good enough before we reach our favorite $n$.
	
	\onslide<+>{}
	$$\tikz{
		\path(0,0)circle(2pt)(0,4)circle(2pt);
		\channeltree0<6:8v49v128;
		\onslide<.(2)->{\draw[alerted text.fg](\insertoverlaynumber-1,1/4)--(7,1/4)
			node[right]{threshold $Î¸$};}
	}$$
	
	\onslide<.(2)->{Why do we apply transform any further? (Answer: we don't!)}
}

\frame{{Prune the other side}
	Sometimes, the top channel is too bad.	\\
	Do we expect any of its descendants to be good enough?
	
	\onslide<+>{}
	$$\tikz{
		\path(0,0)circle(2pt)(0,4)circle(2pt);
		\channeltree0<6:8v49v120;
		\onslide<.(3)->{\draw[example text.fg](\insertoverlaynumber-1,4-1/4)--(7,4-1/4)
			node[right]{threshold $1-Î¸$};}
		\onslide<.(2)->{\draw[alerted text.fg](\insertoverlaynumber-1,1/4)--(7,1/4)
			node[right]{threshold $Î¸$};}
	}$$
	
	\onslide<.(3)->{We don't.}
}

\frame{{Stopping time analysis}
	$ğ˜_n$ has children/needs further transformation if $Î¸<ğ˜_n<1-Î¸$.
	\pp
	Set $Î¸=N^{-10}$; assume $m>O(ã’(ã’N))$, then $e^{-2^{Ï€m}}<Î¸$.
	\pp
	Then $ğ˜—\{ğ˜_m<Î¸\}>ğ˜—ï½›ğ˜_m<e^{-2^{Ï€m}}ï½â‰¥H(W)-â„“^{-Ïm}$
	and $ğ˜—\{ğ˜_m>1-Î¸\}>ğ˜—ï½›H_m>1-e^{-2^{Ï€m}}ï½â‰¥1-H(W)-â„“^{-Ïm}$
	\pp
	That is to say, $ğ˜—\{Î¸<ğ˜_m<1-Î¸\}â‰¤2â„“^{-Ïm}$, hard to stay in the middle.
}

\frame{{Geometric complexity}
	Complexity $=$ \#transformations $=âˆ‘Â¬_{m=0}^nğ˜—\{Î¸<ğ˜_m<1-Î¸\}$.
	\pp
	$$\begin{cases}
		âˆ‘Â¬_{m=O(ã’(ã’N))}^nğ˜—\{Î¸<ğ˜_m<1-Î¸\}â‰¤âˆ‘Â¬_{m=O(ã’(ã’N))}^n2â„“^{-Ïm}=O(1),	\\
		âˆ‘Â¬_{m=0}^{O(ã’(ã’N))}ğ˜—\{Î¸<ğ˜_m<1-Î¸\}â‰¤âˆ‘Â¬_{m=0}^{O(ã’(ã’N))}1=O(ã’(ã’N)).
	\end{cases}$$
	\pp
	Complexity is $O(ã’(ã’N))$ per bit, or $O(Nã’(ã’N))$ per block.
}

\frame{{Summary of pruning and whatnot}
	\pp
	There exist codes with complexity $O(ã’(ã’N))$ per bit,	\\
	error probability $\P<N^{-9}$, and code rate $R=C-N^{-Ï}$.
	\pp
	(Earlier) we have codes with complexity $O(ã’N)$ per bit,	\\
	error probability $\P<e^{-N^Ï€}$, and code rate $R>C-N^{-Ï}$.
	\pp
	Are there codes in between? Yes, continuously.
}

\frame{{Summary}
	Log-log code taken from (with Duursma)	\\
	Log-logarithmic Time Pruned Polar Coding	\\
	\url{https://ieeexplore.ieee.org/document/9274497}.
	
	MDP code taken from (with Duursma)	\\
	Polar Codes' Simplicity, Random Codes' Durability	\\
	\url{https://ieeexplore.ieee.org/document/9274521}.
}

\frame{{Question?}
	\inserttitlegraphic
	
	Predefined questions:	\\
	What does each chapter in dissertation do?	\\
	Why input alphabet is finite field? What is the  advantage?	\\
	Definition of Bhattacharyya parameter?	\\
	References for XYZ?	\\
	Your contribution over others?	\\
	Future plan?
}

\def\appendixname{Appendix}
\appendix

\pgfplotstableread{
		Code				Error			Gap			Complexity		Channel		
		random				e^{-N^Ï€}		N^{-Ï}		\exp(N)			DMC			
		concatenation		e^{-N^Ï€}		â†’0			\poly(N)		DMC			
		RM					â†’0				â†’0			O(N^2)			BEC			
		LDPC				â†’0				â†’0			â€ unclearâ€ 		SBDMC		
		{RA family}			â†’0				â†’0			O(1)			BEC			
		old~prune			e^{-N^{1/2}}	O(1)		Î˜(ã’N)			SBDMC		
		{loglog-polar [W.]}	e^{-n^Ï„}		N^{-Ï}		O(ã’(ã’N))		DMC			
		{MDP-polar [W.]}	e^{-N^Ï€}		N^{-Ï}		O(ã’N)			DMC			
}\tableComplex
\pgfplotstablemodifyeachcolumnelement{Error}\of\tableComplex\as\cell
	{\edef\cell{$\unexpanded\expandafter{\cell}$}}
\pgfplotstablemodifyeachcolumnelement{Gap}\of\tableComplex\as\cell
	{\edef\cell{$\unexpanded\expandafter{\cell}$}}
\pgfplotstablemodifyeachcolumnelement{Complexity}\of\tableComplex\as\cell
	{\edef\cell{$\unexpanded\expandafter{\cell}$}}
\frame{
	$$\pgfplotstabletypeset\tableComplex$$
}

\def\decodecontent#1#2\relax{
	\if\pgfplotstablecol0	\assigncontent{#1#2}
	\else\if#1w				\assigncontent{[W.]}
	\else					\assigncontent{\footnotesize\cite{#1#2}}
	\fi\fi
}
\frame{
	$$\pgfplotstabletypeset[
		every head row/.style={
			before row=\toprule&\multicolumn5c{Symmetric}&\multicolumn2c{Asymmetric}\\,
			after row=\midrule},
		assign cell content/.code={\decodecontent####1\relax}
	]\tableRefarray$$
}

æ¿€Â®{\color{alerted text.fg}}
\frame{{Input alphabet [new idea]}
	$\begin{bmatrix}
		W(yâ‚|1)		&	W(yâ‚‚|1)		&	W(yâ‚ƒ|1)		&	â‹¯	\\
		W(yâ‚|2)		&	W(yâ‚‚|2)		&	W(yâ‚ƒ|2)		&	â‹¯	\\
		W(yâ‚|3)		&	W(yâ‚‚|3)		&	W(yâ‚ƒ|3)		&	â‹¯	\\
		W(yâ‚|4)		&	W(yâ‚‚|4)		&	W(yâ‚ƒ|4)		&	â‹¯	\\
		W(yâ‚|5)		&	W(yâ‚‚|5)		&	W(yâ‚ƒ|5)		&	â‹¯	\\
		W(yâ‚|6)		&	W(yâ‚‚|6)		&	W(yâ‚ƒ|6)		&	â‹¯	\\
		Â®W(yâ‚|6)	&	Â®W(yâ‚‚|6)	&	Â®W(yâ‚ƒ|6)	&	Â®â‹¯	\\
	\end{bmatrix}$
	\qquad
	\tikz[x=4em,y=-2em,baseline=-8em]{
		\draw[line width=1em+2*rule_thickness,postaction={draw=bg,line width=1em}]
			(-1,1)--(-1,7)(0,1)--(0,6)(1,1)--(1,6);
		\fill
			foreach\y in{1,...,7}{(-1,\y)circle(2pt)}
			foreach\y in{1,...,6}{(0,\y)circle(2pt)}
			foreach\y in{1,...,6}{(1,\y)circle(2pt)}
		;
		\draw[shorten <=3pt,shorten >=3pt]
			foreach\y in{1,...,6}{(-1,\y)edge[->](0,\y)}
			(-1,7)edge[->,alerted text.fg](0,6)
			foreach\y in{1,...,6}{
				(0,\y)edge[->](1,1+rnd*5)edge[->](1,1+rnd*5)
			}
		;
	}
}

\frame{{Asymmetric channels \cite{HY13}}
	Recall $U_j$ is the coordinate as in $Xâ‚^â„“â‰”Uâ‚^â„“Â·G$.	\\
	The difficulty of asymmetric channels is $U_j$ being nonuniform and dependent.
	
	Define synthetic channelÂ $\Q iâ‰”(U_iï½œU_1^{i-1})$.	\\
	Define tree $\Q i,\QQ ij,\QQQ ijk,â€¦$; define channel process $\{ğ˜˜_n\}$.	\\
	It polarizes, and at the same pace.
	
	High $H(ğ˜˜_n)$ low $H(ğ˜_n)$ vs both high vs both low.
}

\frame{{Bhattacharyya parameter}
	Binary $Z(W)â‰”âˆ‘Â¬_{yâˆˆğ’´}âˆš{W(y|0)W(y|1)}$.
	
	Non-binary
	$â‰”Ã·1{q-1}âˆ‘Â¬_{\substack{x,x'âˆˆğ”½_q\\xâ‰ x'}}âˆ‘Â¬_{yâˆˆğ’´}âˆš{W(x,y)W(x',y)}$. \\
	{}[New idea] $â‰”\maxÂ¬_{0â‰ dâˆˆğ”½_q}âˆ‘Â¬_{xâˆˆğ”½_q}âˆ‘Â¬_{yâˆˆğ’´}âˆš{W(x,y)W(x+d,y)}.$
}

\frame{{A List of Important Contributions (Chronological)}
	A combinatorial trick to recover scaling exponent (een13 $â†’$ elpin).
	
	The pruning technique/stopping time analysis/log-log complexity.
	
	Improved combinatorial trick (en23 $â†’$ een13 $â†’$ elpin).
	
	Dynamic kernel, later random dynamic kernel.
	
	Alphabet reduction to finite field (trivial but powerful and last mile).
	
	Improve definition of Bhattacharyya parameter, then and FTPC$Z$.
	
	Reducing local CLT to noisy-channel and wiretap-channel coding.
	
	For wiretap bound, extend the universal bound via continuation.
	
	A topological argument to show positive $Ï±$ (that is, CLTâ‹†).
}

%%%% Bi-HÃ¶lder toll

\tiny
\advance\lineskip0ptplus1em
\advance\baselineskip0ptplus1em
\setbeamertemplate{bibliography item}[text]
\setbeamertemplate{bibliography entry author}{\bgroup}
\setbeamercolor{bibliography entry author}{fg=alerted text.fg}
\setbeamercolor{bibliography entry location}{fg=normal text.fg}
\setbeamertemplate{bibliography entry note}{\egroup}
\bibliographystyle{alphaurl}
\bibliography{Chilly-beamer}
\vfil\hbox{}

\frame{}

\end{document}




